{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEnxYDKtUebdZ2zYoswM62",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7898c73346740968f731e73171bca3b": {
          "model_module": "jupyter-webrtc",
          "model_name": "CameraStreamModel",
          "model_module_version": "~0.6.0",
          "state": {
            "_view_name": "MediaStreamView",
            "_dom_classes": [],
            "_model_name": "CameraStreamModel",
            "_view_module": "jupyter-webrtc",
            "_model_module_version": "~0.6.0",
            "_view_count": null,
            "_view_module_version": "~0.6.0",
            "layout": "IPY_MODEL_db796b8aa4a64478a3697d59d2c79791",
            "_model_module": "jupyter-webrtc",
            "constraints": {
              "facing_mode": "user",
              "video": {
                "width": 640,
                "height": 480
              },
              "audio": false
            }
          }
        },
        "db796b8aa4a64478a3697d59d2c79791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a58c0230167a4778921e21bcee4f61b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ImageView",
            "_dom_classes": [],
            "_model_name": "ImageModel",
            "format": "png",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "width": "640px",
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_635e51952ee44f8990e8fed18655e4ca",
            "height": "480px",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "635e51952ee44f8990e8fed18655e4ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6aafc4ec7cd4a85a269e550b700d285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khpankiv/Try/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506,
          "referenced_widgets": [
            "e7898c73346740968f731e73171bca3b",
            "db796b8aa4a64478a3697d59d2c79791"
          ]
        },
        "id": "_8vvvfQ65hQi",
        "outputId": "5e9b723d-67dc-4138-b83f-323f3d157fc2"
      },
      "source": [
        "from ipywebrtc import CameraStream, ImageRecorder\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "camera = CameraStream(constraints=\n",
        "                      {'facing_mode': 'user',\n",
        "                       'audio': False,\n",
        "                       'video': { 'width': 640, 'height': 480 }\n",
        "                       })\n",
        "camera\n",
        "#while True:\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7898c73346740968f731e73171bca3b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "CameraStream(constraints={'facing_mode': 'user', 'audio': False, 'video': {'width': 640, 'height': 480}})"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/a8874ba6619b6106/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506,
          "referenced_widgets": [
            "a58c0230167a4778921e21bcee4f61b6",
            "635e51952ee44f8990e8fed18655e4ca",
            "e7898c73346740968f731e73171bca3b",
            "a6aafc4ec7cd4a85a269e550b700d285",
            "db796b8aa4a64478a3697d59d2c79791"
          ]
        },
        "id": "zzPF6G41efp_",
        "outputId": "5b228058-e210-4bec-b225-8b393d30f10f"
      },
      "source": [
        "image_recorder = ImageRecorder(stream=camera,)\n",
        "image_recorder.recording = True\n",
        "image_recorder.autosave = False\n",
        "#image_recorder.download()\n",
        "frame=image_recorder.image\n",
        "frame."
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a58c0230167a4778921e21bcee4f61b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Image(value=b'')"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/a8874ba6619b6106/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "o2EAQ751aKQ-",
        "outputId": "7486170f-3d25-4492-eec4-56e677047872"
      },
      "source": [
        "#From example\n",
        "import cv2\n",
        "from ipywebrtc import CameraStream, ImageRecorder\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "camera = CameraStream(constraints=\n",
        "                      {'facing_mode': 'user',\n",
        "                       'audio': False,\n",
        "                       'video': { 'width': 640, 'height': 480 }\n",
        "                       })\n",
        "image_recorder = ImageRecorder(stream=camera,)\n",
        "image_recorder.recording = True\n",
        "image_recorder.autosave = False\n",
        "#image_recorder.download()\n",
        "frame=image_recorder.image\n",
        "frame\n",
        "\n",
        "# parameters for loading data and images\n",
        "detection_model_path = 'haarcascade_files/haarcascade_frontalface_default.xml'\n",
        "emotion_model_path = 'Try/_mini_XCEPTION.102-0.66.hdf5'\n",
        "\n",
        "# hyper-parameters for bounding boxes shape\n",
        "# loading models\n",
        "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
        "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
        "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
        " \"neutral\"]\n",
        "\n",
        "#feelings_faces = []\n",
        "#for index, emotion in enumerate(EMOTIONS):\n",
        "\n",
        "while True:\n",
        "    #frame = image_recorder\n",
        "    #print(frame)\n",
        "    #reading the frame\n",
        "    frame = imutils.resize(frame,width=300)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "    print('jygiyg')\n",
        "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
        "    frameClone = frame.copy()\n",
        "    if len(faces) > 0:\n",
        "        faces = sorted(faces, reverse=True,\n",
        "        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
        "        (fX, fY, fW, fH) = faces\n",
        "                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 28x28 pixels, and then prepare\n",
        "            # the ROI for classification via the CNN\n",
        "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
        "        roi = cv2.resize(roi, (64, 64))\n",
        "        roi = roi.astype(\"float\") / 255.0\n",
        "        roi = img_to_array(roi)\n",
        "        roi = np.expand_dims(roi, axis=0)\n",
        "        \n",
        "        \n",
        "        preds = emotion_classifier.predict(roi)[0]\n",
        "        emotion_probability = np.max(preds)\n",
        "        label = EMOTIONS[preds.argmax()]\n",
        "    else: continue\n",
        "\n",
        " \n",
        "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
        "                # construct the label text\n",
        "                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
        "\n",
        "                # draw the label + probability bar on the canvas\n",
        "               # emoji_face = feelings_faces[np.argmax(preds)]\n",
        "\n",
        "                \n",
        "                w = int(prob * 300)\n",
        "                cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
        "                (w, (i * 35) + 35), (0, 0, 255), -1)\n",
        "                cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
        "                (255, 255, 255), 2)\n",
        "                cv2.putText(frameClone, label, (fX, fY - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "                cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
        "                              (0, 0, 255), 2)\n",
        "#    for c in range(0, 3):\n",
        "#        frame[200:320, 10:130, c] = emoji_face[:, :, c] * \\\n",
        "#        (emoji_face[:, :, 3] / 255.0) + frame[200:320,\n",
        "#        10:130, c] * (1.0 - emoji_face[:, :, 3] / 255.0)\n",
        "\n",
        "\n",
        "    cv2_imshow('your_face', frameClone)\n",
        "    cv2_imshow(\"Probabilities\", canvas)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "camera.release()\n",
        "#cv2.destroyAllWindows()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ce6f78f32f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#print(frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#reading the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaleFactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminNeighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCASCADE_SCALE_IMAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imutils/convenience.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, width, height, inter)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# grab the image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# if both the width and height are None, then return the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxIQuBOjTSlf"
      },
      "source": [
        "! pip install ipywebrtc  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt4mF8MxSh4A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}